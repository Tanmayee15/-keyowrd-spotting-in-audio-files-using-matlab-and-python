import librosa
import speech_recognition as sr
import numpy as np
import matplotlib.pyplot as plt

# Load and preprocess the audio file
def load_audio(file_path):
    y, sr = librosa.load(file_path, mono=True)
    return y, sr

# Transcribe audio using SpeechRecognition
def transcribe_audio(audio_file):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)
        text = recognizer.recognize_google(audio_data)
    return text

# Improved voice gender identification based on pitch
def identify_gender(audio_data, sr):
    fmin = librosa.note_to_hz('C2')
    fmax = librosa.note_to_hz('C6')
    pitches, voiced_flags, voiced_probs = librosa.pyin(audio_data, fmin=fmin, fmax=fmax)
    valid_pitches = pitches[voiced_flags]  # Filter out unvoiced segments
    if len(valid_pitches) == 0:
        return 'Unknown'
    avg_pitch = np.mean(valid_pitches)
    # Typical pitch ranges for male and female voices (simplified)
    if avg_pitch < 165:
        return 'Male'
    else:
        return 'Female'

# Main function to perform keyword spotting and gender identification
def keyword_spotting_and_gender_identification(audio_file, keywords):
    y, sr = load_audio(audio_file)
    transcription = transcribe_audio(audio_file)
    gender = identify_gender(y, sr)
    
    words = transcription.split()
    word_durations = len(y) / sr / len(words)  # Average duration of each word
    occurrences = {}
    keyword_timestamps = {}

    for keyword in keywords:
        occurrences[keyword] = {'count': 0, 'timestamps': []}
        for i, word in enumerate(words):
            if keyword.lower() in word.lower():
                occurrences[keyword]['count'] += 1
                timestamp = i * word_durations
                occurrences[keyword]['timestamps'].append(timestamp)
                if keyword not in keyword_timestamps:
                    keyword_timestamps[keyword] = []
                keyword_timestamps[keyword].append(timestamp)
    
    print("Occurrences of given keywords:", occurrences)
    plot_keyword_occurrences(y, sr, keyword_timestamps)
    return occurrences, gender

# Plot keyword occurrences on the waveform graph
def plot_keyword_occurrences(y, sr, keyword_timestamps):
    plt.figure(figsize=(14, 5))
    librosa.display.waveshow(y, sr=sr, alpha=0.6)
    
    # Define different colors and line styles for different keywords
    colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']
    line_styles = ['-', '--', '-.', ':']
    color_idx = 0
    style_idx = 0
    
    for keyword, timestamps in keyword_timestamps.items():
        color = colors[color_idx % len(colors)]
        line_style = line_styles[style_idx % len(line_styles)]
        for timestamp in timestamps:
            plt.axvline(x=timestamp, color=color, linestyle=line_style, alpha=0.8, label=keyword)
        color_idx += 1
        style_idx += 1
    
    # To avoid duplicate labels in the legend
    handles, labels = plt.gca().get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    plt.legend(by_label.values(), by_label.keys())
    
    plt.title('Keyword Occurrences in Audio')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.show()

# Example usage
audio_file_path = 'female3.wav'
keywords = ['hi', 'hello', 'yes']
occurrences, gender = keyword_spotting_and_gender_identification(audio_file_path, keywords)
print("Gender Identified:", gender)